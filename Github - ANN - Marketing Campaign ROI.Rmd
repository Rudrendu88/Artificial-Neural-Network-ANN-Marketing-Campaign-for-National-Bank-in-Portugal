---
title: "Artificial Neural Network (ANN) for improving Marketing Campaign ROI for National Bank at Portugal"
output: html_notebook
---


```{r}
# Importing the dataset
d=read.table("bank-additional-full.csv",header=TRUE,sep=";")
dataset = data.frame(d)
dim(dataset)
str(dataset)

# Checking for missing data
d3=dataset
for(i in 1:ncol(d3))
   {
    print(colnames(d3[i]))
    print(sum(is.na(d3[i])))
}

# Removing Missing Data in the form of "unknown"
dataset[dataset == "unknown"] = NA
dataset = na.omit(dataset)
dim(dataset)

# Encoding the categorical & numerical variables in dataset
dataset$age = as.numeric(dataset$age)
dataset$job = as.factor(dataset$job)
dataset$job = as.factor(dataset$job)
dataset$marital = as.factor(dataset$marital)
dataset$education = as.factor(dataset$education)
dataset$default = as.factor(dataset$default)
dataset$housing = as.factor(dataset$housing)
dataset$loan = as.factor(dataset$loan)
dataset$contact = as.factor(dataset$contact)
dataset$month = as.factor(dataset$month)
dataset$day_of_week = as.factor(dataset$day_of_week)
dataset$duration = as.numeric(dataset$duration)
dataset$campaign = as.numeric(dataset$campaign)
dataset$pdays = as.numeric(dataset$pdays)
dataset$previous = as.numeric(dataset$previous)
dataset$poutcome = as.factor(dataset$poutcome)
dataset$emp.var.rate = as.numeric(dataset$emp.var.rate)
dataset$cons.price.idx = as.numeric(dataset$cons.price.idx)
dataset$cons.conf.idx = as.numeric(dataset$cons.conf.idx)
dataset$euribor3m = as.numeric(dataset$euribor3m)
dataset$nr.employed = as.numeric(dataset$nr.employed)

dataset$y = ifelse(dataset$y == "yes",1,0)
dataset$y = as.factor(dataset$y)

str(dataset)

```

```{r}

# Splitting the dataset into the Training set and Test set

library(caTools)
set.seed(123)
split = sample.split(dataset$y, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling
training_set[,c(1,11:14,16:20)] = scale(training_set[,c(1,11:14,16:20)])
test_set[,c(1,11:14,16:20)] = scale(test_set[,c(1,11:14,16:20)])


```


```{r}
# Fitting ANN to the Training set
# Nodes in hidden layers selected by Avg (# Input + # Output Nodes) = (21+1)/2 = 11 
#install.packages('h2o')
library(h2o)
h2o.init(ip = "localhost")
model = h2o.deeplearning(y = 21,
                         training_frame = as.h2o(training_set),
                         activation = 'Rectifier',
                         hidden = c(11,11),
                         epochs = 100,
                         train_samples_per_iteration = -2)

# Predicting the Test set results
y_pred = h2o.predict(model, newdata = as.h2o(test_set[-21]))
str(y_pred)
dim(test_set)

y_pred=y_pred[1]
y_pred = as.vector(y_pred)

# Making the Confusion Matrix
cm = table(test_set[, 21], y_pred)
print(cm)

Model_Accuracy=(cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2])

print(" Model Accuracy is") 
print(Model_Accuracy)

h2o.shutdown()

```

